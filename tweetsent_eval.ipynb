{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hugging tweetsent get_benchmarks.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3wy72h_Xxzq",
        "colab_type": "text"
      },
      "source": [
        "Get official evaluation script "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njm6ce3AXZKb",
        "colab_type": "code",
        "outputId": "3e8a347d-4ebe-44b3-bd21-42d42e25a966",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "!git clone https://bitbucket.org/HBrum/tweetsentbr.git\n",
        "%cd tweetsentbr/sent-analysis/\n",
        "!pip install nlpnet"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'tweetsentbr'...\n",
            "remote: Counting objects: 85, done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 85 (delta 20), reused 0 (delta 0)\u001b[K\n",
            "Unpacking objects: 100% (85/85), done.\n",
            "/content/transformers/tweetsentbr/sent-analysis\n",
            "Collecting nlpnet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/3f/a5bf348da1a3148acb810d5236bd1c832383fd1a98cb9c4ac3f3bf92ab72/nlpnet-1.2.4.tar.gz (393kB)\n",
            "\u001b[K     |████████████████████████████████| 399kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from nlpnet) (1.18.2)\n",
            "Requirement already satisfied: nltk>=3.2.2 in /usr/local/lib/python3.6/dist-packages (from nlpnet) (3.2.5)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from nlpnet) (1.12.0)\n",
            "Requirement already satisfied: h5py>=2.8.0rc1 in /usr/local/lib/python3.6/dist-packages (from nlpnet) (2.10.0)\n",
            "Building wheels for collected packages: nlpnet\n",
            "  Building wheel for nlpnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nlpnet: filename=nlpnet-1.2.4-cp36-cp36m-linux_x86_64.whl size=1543865 sha256=dab4fab3e0728e5a24938e54c7b04738d8054924b6570ec914e67a44f10ca959\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/e0/52/d5159182627fa071d9d9ec802808491e3bc851821769d7160e\n",
            "Successfully built nlpnet\n",
            "Installing collected packages: nlpnet\n",
            "Successfully installed nlpnet-1.2.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xn2EP0PgJQ_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = 'roberta-large'\n",
        "#neuralmind/bert-base-portuguese-cased, bert-base-multilingual-cased, roberta-large\n",
        "filepath = f'../../output/{model}/tweetsent/predictions.json'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5y45Z35FMks",
        "colab_type": "text"
      },
      "source": [
        "Gerar *scores*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfFBDHbCZI5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from importlib import reload  \n",
        "from classify import report\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "dataset = pd.read_csv('tweetsent_test.tsv', header = None, sep = '\\t')\n",
        "\n",
        "with open(filepath) as f:\n",
        "    predictions = json.load(f)\n",
        "\n",
        "number = {'Negative': 0, 'Neutral': 1, 'Positive': 2}\n",
        "y_test = dataset[1].map(number)\n",
        "\n",
        "report(None, predictions, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}